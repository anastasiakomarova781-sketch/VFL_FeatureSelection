================================================================================
                    FedSDG-FS: Federated Stochastic Dual-Gate Feature Selection
                    Вертикальное федеративное обучение с отбором признаков
================================================================================

БЫСТРЫЙ СТАРТ - КОМАНДЫ ЗАПУСКА
================================================================================

1. УСТАНОВКА ЗАВИСИМОСТЕЙ
--------------------------
pip install -r requirements.txt

Или вручную:
pip install numpy pandas scikit-learn phe

2. ЗАПУСК МЕТОДА (из корня проекта)
------------------------------------
python3 fedsdg/run_fedsdg_fs.py

Или из папки fedsdg:
cd fedsdg
python3 run_fedsdg_fs.py

3. НАСТРОЙКА ПАРАМЕТРОВ
-----------------------
Откройте файл fedsdg/run_fedsdg_fs.py и измените параметры:

USE_SAMPLE = True      # True = использовать подвыборку (быстро)
                       # False = использовать весь датасет (медленно)
SAMPLE_SIZE = 1000     # Количество образцов для тестирования
MAX_ITER = 10          # Количество итераций обучения

В файле fedsdg/fedsdg_fs_article.py можно изменить:
USE_ENCRYPTION = False # False = без шифрования (быстро для тестирования)
                       # True = с шифрованием Paillier (медленно, но безопасно)

4. ПАРАМЕТРЫ МОДЕЛИ
--------------------
model = FedSDGFS(
    n_classes=n_classes,  # Количество классов (определяется автоматически)
    lr=0.05,              # Скорость обучения (learning rate)
    lambda_reg=0.01,      # Коэффициент регуляризации L2
    temperature=0.1,      # Температура для Concrete/Gumbel-Sigmoid
    max_iter=10,          # Максимальное количество итераций
    threshold=0.5         # Порог отбора признаков (0.0 - 1.0)
)

ПРИМЕР ИСПОЛЬЗОВАНИЯ
================================================================================

1. Подготовьте данные в формате CSV с обязательными столбцами 'id' и 'target'
   (для активного датасета)

2. Разместите файлы в папке Data/

3. Запустите скрипт:
   python3 fedsdg/run_fedsdg_fs.py

4. Результаты будут сохранены в:
   - Data/active_dataset_selected.csv
   - Data/passive_dataset_selected.csv

5. В консоли будет выведена информация о:
   - Загруженных данных
   - Прогрессе обучения
   - Отобранных признаках для каждой стороны
   - Значениях gates (вероятностях) для всех признаков

ОПИСАНИЕ МЕТОДА
================================================================================

FedSDG-FS (Federated Stochastic Dual-Gate Feature Selection) - это метод отбора 
признаков для вертикального федеративного обучения (Vertical Federated Learning, VFL).

Метод позволяет нескольким участникам совместно выбирать важные признаки из 
разделенных данных, не раскрывая исходные данные друг другу.

ОСНОВНЫЕ КОМПОНЕНТЫ
================================================================================

1. Активный клиент (Active Party):
   - Имеет доступ к целевой переменной (таргету)
   - Выступает в роли координатора
   - Генерирует и шифрует индикаторную матрицу классов
   - Вычисляет важность признаков на основе метрики Gini
   - Агрегирует результаты от всех участников

2. Пассивный клиент (Passive Party):
   - Не имеет доступа к целевой переменной
   - Участвует в выборе признаков
   - Оценивает важность своих признаков через корреляцию со скрытыми предсказаниями
   - Шифрует свои данные перед отправкой

3. Стохастический двойной гейт (Dual Gate):
   - Selection Gate: определяет, будет ли признак отобран
   - Contribution Gate: определяет вклад признака в модель
   - Оба gates обновляются одновременно в процессе обучения

ЭТАПЫ РАБОТЫ МЕТОДА
================================================================================

ЭТАП 1: Подготовка и инициализация
----------------------------------
- Активная сторона генерирует индикаторную матрицу классов (one-hot encoding)
- Матрица шифруется с использованием гомоморфного шифрования Paillier
- Зашифрованная матрица отправляется пассивным участникам

ЭТАП 2: Выбор важных признаков во время обучения
-------------------------------------------------
- Каждый клиент случайным образом выбирает образцы или мини-батчи
- Для каждого признака применяется стохастический двойной гейт (stochastic dual-gate)
- Гейт определяет вероятность участия признака в глобальной модели
- Клиент вычисляет маскированные эмбеддинги и шифрует их перед отправкой

ЭТАП 3: Защищенная прямая передача (Forward Propagation)
---------------------------------------------------------
- Сервер (активная сторона) получает зашифрованные эмбеддинги от пассивных клиентов
- Вычисляет взвешенные суммы с добавлением случайного шума для защиты приватности
- Отправляет результаты обратно клиентам

ЭТАП 4: Защищенная обратная передача (Backward Propagation)
------------------------------------------------------------
- Сервер вычисляет градиенты потерь
- Шифрует градиенты и отправляет клиентам для обновления локальных моделей
- Клиенты удаляют шум, обновляют параметры и параметры стохастических гейтов

ЭТАП 5: Оптимизация и обновление
---------------------------------
- Алгоритм повторяет прямую и обратную передачи для всех мини-батчей
- Стохастические гейты адаптивно повышают вероятность выбора важных признаков
- Процесс продолжается до сходимости глобальной модели

ЭТАП 6: Финальный отбор признаков
----------------------------------
- На основе финальных значений gates принимается решение об отборе признаков
- Признаки с gates выше порога (threshold) считаются важными и остаются в модели
- Результатом является глобальная модель с высокой точностью и выбранный набор признаков

ПРЕИМУЩЕСТВА МЕТОДА
================================================================================

1. Контекстная релевантность:
   - Выбираются признаки, релевантные конкретной модели
   - Отбор происходит с учетом взаимодействия признаков

2. Эффективность:
   - Фильтруются шумные признаки до обучения
   - Уменьшается объем передаваемых данных

3. Безопасность:
   - Данные и метки не раскрываются никакой стороне
   - Используется гомоморфное шифрование Paillier
   - Добавляется случайный шум для дополнительной защиты

СТРУКТУРА ПРОЕКТА
================================================================================

VFL_FeatureSelection/
├── fedsdg/                          # Основная папка с реализацией
│   ├── fedsdg_fs_article.py        # Реализация алгоритма FedSDG-FS
│   ├── run_fedsdg_fs.py            # Скрипт для запуска метода
│   └── README_FedSDG.txt           # Этот файл
├── Data/                            # Данные
│   ├── active_dataset_test.csv     # Активный датасет (с таргетом)
│   ├── passive_dataset_test.csv    # Пассивный датасет (без таргета)
│   ├── active_dataset_selected.csv # Результат: отобранные активные признаки
│   └── passive_dataset_selected.csv # Результат: отобранные пассивные признаки
├── Files/
│   └── 2302.10417v1.pdf           # Научная статья по методу
├── requirements.txt                # Зависимости Python
└── README.txt                      # Общая документация проекта

ФОРМАТ ВХОДНЫХ ДАННЫХ
================================================================================

Активный датасет (active_dataset_test.csv):
- Обязательные столбцы: 'id', 'target'
- Столбцы с признаками: любые другие столбцы (например, feat_a_00, feat_a_01, ...)

Пассивный датасет (passive_dataset_test.csv):
- Обязательные столбцы: 'id'
- Столбцы с признаками: любые другие столбцы (например, feat_b_00, feat_b_01, ...)

ВАЖНО: Оба датасета должны иметь общие значения в столбце 'id' для выравнивания данных.

ФОРМАТ ВЫХОДНЫХ ДАННЫХ
================================================================================

active_dataset_selected.csv:
- Столбцы: 'id', 'target', + отобранные активные признаки

passive_dataset_selected.csv:
- Столбцы: 'id', + отобранные пассивные признаки

ПРОИЗВОДИТЕЛЬНОСТЬ
================================================================================

БЕЗ ШИФРОВАНИЯ (USE_ENCRYPTION = False):
- 1000 образцов, 10 итераций: ~10-30 секунд
- 10000 образцов, 50 итераций: ~5-10 минут

С ШИФРОВАНИЕМ (USE_ENCRYPTION = True):
- 1000 образцов, 10 итераций: ~10-30 минут
- 10000 образцов, 50 итераций: ~несколько часов

РЕКОМЕНДАЦИИ:
- Для тестирования: USE_ENCRYPTION = False, USE_SAMPLE = True, SAMPLE_SIZE = 1000
- Для продакшена: USE_ENCRYPTION = True, USE_SAMPLE = False

УСТРАНЕНИЕ ПРОБЛЕМ
================================================================================

Проблема: "ModuleNotFoundError: No module named 'pandas'"
Решение: Установите зависимости: pip install -r requirements.txt

Проблема: "ValueError: operands could not be broadcast together"
Решение: Убедитесь, что данные выровнены по id и имеют одинаковое количество строк

Проблема: Код работает очень медленно
Решение: Установите USE_ENCRYPTION = False и USE_SAMPLE = True для быстрого тестирования

Проблема: Не отобраны признаки
Решение: Уменьшите threshold (например, 0.3) или увеличьте MAX_ITER

ДОПОЛНИТЕЛЬНАЯ ИНФОРМАЦИЯ
================================================================================

Научная статья: Files/2302.10417v1.pdf
Алгоритм: FedSDG-FS (Federated Stochastic Dual-Gate Feature Selection)
Шифрование: Paillier Homomorphic Encryption
Фреймворк: Совместимо с FATE Framework

================================================================================
                            Конец документации
================================================================================




